---
{"dg-publish":true,"permalink":"/030 PKV/AI/基础/【ML基础】从特征组合及其权重的角度对常用模型做统一解释 - 2022H1/"}
---

## 总思路

如果把机器学习理解为**对输入`x`的组合空间的表征**，那该表征主要包括「特征组合方式」和「其对应权重（weight）」两个核心要素。另外，表示特征方式包括：原始特征值（$x_i$, $x_j$）和特征向量embvec（$e_i$, $e_j$），$e_i * e_j$表示$e_i$和$e_j$的dot-product。

## 常用模型的统一解释

基于上述两个核心要素的算法对比：

1. `树模型/gbdt`：每棵树的leaf node对应的预测结果（response），可以理解为从根节点到该leaf node的路径上所有特征的交叉的weight。

2. `mlp/lr`：不具有直接原始特征值交叉的能力（所以需要人工交叉），但可以理解为通过线性加权（weight）的方式做全部特征的“弱”交叉，需要使用非线性激活函数来解决非线性问题。

3. `fm/ffm`：直接的二阶原始特征值交叉（$x_i$_*$x_j$_），_weight_为$e_i * e_j$，即由特征向量embvec内积得到，和self-attention一样(q_i*k_j)。fm也可称为二阶特征向量embvec的交叉（$x_i$, $x_j$一般为1，可忽略）。

4. `transformer 或 self-attention`：token/特征$e_i$的交互方式为$softmax(W_q*e_i  * W_k*e_{1…n}) * W_v*e_{1…n}$。与fm相比都是基于特征向量，但`transformer`除了有和`fm`一样的$q_i*k_j$，又做了`softmax`归一化和对`v_i`的`weighted sum`（_`fm`没有做`softmax`且$v_j$换成了$x_i$*_$x_j$）；而且`transformer`是多层+`FFN`（获取更深、泛化性更好的交互），`fm`为一层。
	1. 适用场景：组合空间大 且 链接稠密（共现性高）、高质量数据多
	2. 一层`transformer`也是二阶交叉，多层则“变相”实现了多阶交叉。`cnn`、`gnn`也类似，`rnn`相当于横向多层
	3. 替换统计特征的难点：1.模型训练batch小，而统计特征是基于全局的统计。2.一些组合特征的共现性低（比如个性化特征），容易过拟合，并会被共现性高的特征影响，而用统计的方式很容易做

5. `cnn`：image每个pixel/特征的embvec为feature map的channel维（即$e_i$, $e_j$）。filter卷积操作即为weighted $e_i$和$e_j$（而self-attention的weight来自$e_i * e_j$，且cnn非全局而是local的）。

6. `ViT`：因为做pixel级embvec的计算量和存储太大，改为一个patch做为一个embvec，然后用self-attention。

7. `lstm`（假设激活函数为`relu`和不考虑bias）：$e_t$和$e_{t-1}$的交叉部分可简化为$W_f*W_i*e_t*e_{t-1}$和$W_i*W_h*e_t*e_{t-1}$，$W_f$为`forget gate`参数，$W_i$为`input gate`参数，$W_h$为$h_t$的参数。

8. `gat/gnn`：类似`cnn`的filter的field，基于特定`node`（$e_i$）的`neighbor nodes`做 $\sum _{1…n} W_i* e_{i}$。

9. `DCN`：construct all the cross terms $x_1^{α_1} * x_2^{α_2} * . . . * x_d^{α_d}$（$\alpha$次幂原始特征值的交叉，非特征向量或embvec交叉） with degree |$\alpha$|>2。理论上基于泰勒公式的幂级数可以拟合任何数据分布或函数，该方法理论基础很好。

## 讨论环节

问题1：$x_i$和$x_j$的组合空间很稀疏，为什么`fm`是有效的？

1. 对特征$x_i$在样本中出现的频次做过滤，保证每个embvec均可训练。
2. 只会通过 样本中出现的特征组合 对 相关的特征表征embvec做BP训练。（如果样本存在模式坍塌或非完备的特征组合分布，会容易过拟合，所以这类方法对样本量的要求远大于基于原始特征值的方案，如lr等）。
3. 特征表征交叉的方式需要训练的参数量远小于「原始特征值笛卡尔积交叉」的方式，从N^2降到N\*k，N为特征field的个数。

欢迎补充。希望基于这种串联加深对各算法的理解和作为平时算法选型的参考。
