---
{"dg-publish":true,"permalink":"/030 PKV/AI/LLM/Chatsum Tech Report/"}
---

## TLDR
1. Pipeline：收集聊天记录数据 -》数据清洗和预处理 -》GPT训练数据生成 -》SFT -》评估 -》服务部署 -》Web App和Bot构建。
2. 数据：主要基于[NaturalConv](https://arxiv.org/abs/2103.02548)数据+GPT生成。
3. 技术选型：因为要基于modelhub的模型，综合评估后`Baichuan2-13b-chat`的全量SFT效果最优。
4. 效果评估：整体效果接近GPT3.5，基于GPT4自动评估100个case，34个分数高于GPT3.5，66个略差但相差不大。（但该Chatsum版本不是我们最新版本。）

## 2. 数据收集和处理
1. 开源多轮多人对话+Summary很少，高质量的更少
2. 数据Pipeline：
	1. train和val数据：NaturalConv过滤掉无信息量的chat、chat分组、GPT生成、基于各基座LLM封装（参考[设计Prompt(提示词)](https://cooper.didichuxing.com/knowledge/share/book/yOnBK5INGvQT/2200923327761)），共约5K+组。
	2. 评估数据：源为各类Wechat群收集而来，共100组，其他逻辑类似train数据。

## 3. 技术选型
1. 闭源模型评估（主要指中文Summary）
	1. GPT4 > GPT3.5 ~= 星火 > minimax
2. 开源模型评估
	1. `baichuan2-13b-chat`略好于`baichuan-13b-chat`，`baichuan-13b-chat`略好于`Llama-2-13b-chat-hf`（部分翻译成中文后），`chatglm2-6b`略差，其他基本不可用。
	2. 虽然`baichuan2-13b-chat`有些Summary能力，但幻觉、语义理解、生成重复等问题严重，无法直接使用。
3. FT方案选型
	1. 一般正常情况下，Full FT的方案相对PEFT更好（[可参考](https://arxiv.org/abs/2110.07602)），虽然成本更高，但modelhub恰好提供，就直接使用。
	2. 调优结论：
		1. 和Pretrain的lr使用相同的lr效果最好
		2. epoch增大loss变小，但也会过拟合
		3. chat比base好（和训练数据量有关）
![Pasted image 20231015183603.png](/img/user/990%20Attachment/Pasted%20image%2020231015183603.png)
## 4. 效果评估
### 4.1 SFT前后对比
* case对比
> SFT前
![Pasted image 20231017230200.png](/img/user/990%20Attachment/Pasted%20image%2020231017230200.png)
> SFT后
![Pasted image 20231017230127.png](/img/user/990%20Attachment/Pasted%20image%2020231017230127.png)
### 4.2 与闭源商用大模型对比
* 基于各类Wechat群收集而来共100组对话，以GPT为基准，效果如下：
	* gpt3.5~=spark(星火) > chatsum（非最新版） > minimax
	* ![Pasted image 20231017224633.png](/img/user/990%20Attachment/Pasted%20image%2020231017224633.png)
* case对比：基于原对话，我们发现相对GPT3.5，Chatsum模型（见4.1部分SFT后）对细节总结更清楚且没有信息缺失。
> GPT3.5
![Pasted image 20231017230620.png](/img/user/990%20Attachment/Pasted%20image%2020231017230620.png)

> 原对话
```
2000_2_1：嗯嗯，因为只有以前的还比较喜欢，也有看头嘛。
2000_2_0：啊，也是，你听说最近的中国羽毛球公开赛那事儿了嘛？
2000_2_1：我不知道诶，我只听说了在常州办，怎么了嘛？
2000_2_0：就是男单那个一哥，就石宇奇啊，你知道吗？
2000_2_1：嗯嗯，知道啊，他不会复出了吧。
2000_2_0：嗯呢，就是复出了，这还是他受伤后第一场比赛呢。
2000_2_1：那他不会爆冷了吧？
2000_2_0：卧槽，你看过这新闻？
2000_2_1：没有啊，听你口气能够猜到一点，真的爆冷了嘛？
2000_2_0：是啊，比赛全场只拿了十四分，就像是来玩儿似的。
2000_2_1：哇，那她不会是没恢复好吧？
2000_2_0：不知道啊，但是有人猜，他是过来蹭积分的。
2000_2_1：啥积分啊？
2000_2_0：奥运会的积分啊，三千积分呢。诶不说了，车到了，再见啊。
2000_2_1：哦哦，那拜拜。
1528_3_0：请问你旁边的座位有人吗？
1528_3_1：没有人的，你坐吧。
1528_3_0：对了，最近Baby参加了阿雅的节目《奇遇人生》你看了吗？
1528_3_1：没有啊，她在节目里都说什么了，有什么好玩的事吗？
1528_3_0：是的，她在节目里被认出，并评论说她老公很爱她，让她不是很高兴。
1528_3_1：是吗，这有什么不高兴，她老公爱她她不应该高兴才对吗？
1528_3_0：因为她觉得别人总把她看成黄晓明的老婆，大家对她还是没有认可。
1528_3_1：哦，这样啊，那她对于这样的看法是怎么说的？
1528_3_0：嗯，她表示会拍出好的作品，让大家都记住她。
1528_3_1：这样啊，那就期待吧，不过Baby是真的漂亮，演技也真是一般。
1528_3_0：是的，不过听她自已话还是感觉她对于自已的表现也不是很满意。
1528_3_1：是啊，不过她这不也说要努力改变现在这种情况嘛。
1528_3_0：是的，而且她对于感情生活的理解还真是很到位。
1528_3_1：是吗？她怎么说的，不会是什么鸡汤吧。
1528_3_0：不是的，她说二个人就像拼图，能拼到一起就证明是对的了。
1528_3_1：嗯，说的很有道理。
1528_3_0：我到了，先下了，拜拜。
1528_3_1：好的，拜拜。
2656_0_0：刚刚看你一直在看体育新闻啊？
2656_0_1：是啊，站点等车时间太长了，顺便翻翻手机关注下。
2656_0_0：有什么有价值的吗？
2656_0_1：体操世锦赛男团比赛上林超攀出现为了失误！
2656_0_0：林超攀是个全能型选手，发挥一向比较稳定的呀。
2656_0_1：是啊，前面的比赛都比较稳定，单杠上出现了点问题。
2656_0_0：那世锦赛最终什么成绩？
2656_0_1：中国队无缘金牌啊！
2656_0_0：好可惜啊！
2656_0_1：是啊，但是能发现问题，去努力提升，也未尝不是好事！
2656_0_0：是的，有目标就不怕突破不了问题。
2656_0_1：是的，林超攀也是这么认为的，这样一来反而能更好的备战奥运会。
2656_0_0：这才是真正的运动员，有股不服输的劲儿，还能知道怎么去弥补修正。
2656_0_1：运动员的确不容易，365天，天天训练，真可谓日复一日，年复一年啊！
2656_0_0：是啊，比赛时要面对的压力也是常人难以想象的。
2656_0_1：哎呀，我到站了，先下车了！
4979_1_0：你这是在看什么啊，这么聚精会神的。
```

> system msg
```
你是一个优秀的对话聊天助手。基于所有多轮聊天记录，你需要逐步完成如下任务，首先，将聊天记录的内容归纳出2-5个核心话题（话题名称要简洁），并简洁的概括出每个人的观点或态度；最后针对每个话题给出总结和要点。
```
