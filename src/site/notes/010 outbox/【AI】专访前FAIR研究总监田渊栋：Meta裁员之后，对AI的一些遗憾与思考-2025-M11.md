---
{"dg-publish":true,"permalink":"/010-outbox/ai-fair-meta-ai-2025-m11/"}
---


## 封面
- 标题：专访前FAIR研究总监田渊栋：Meta裁员之后，对AI的一些遗憾与思考
- 链接：https://www.youtube.com/watch?v=EsaUQNx59vA
- 发布日期：2025-11-11
- 总字数：2965
- 预估阅读时长：约 10 分钟
- 生成时间：2025-11-12 20:36:24
- 覆盖时长：00:39:03

## 摘要总结
- 田渊栋认为：LLM 是“有意思但未必正确”的路线，真正的瓶颈在数据效率。仅靠 Scaling Law（扩展规律）堆数据和算力，通向的是**“资源密集、效率低”**的悲观未来。
- 他强烈看好 RL 的作用：不仅是训练范式差异，更关键是**“主动学习、重塑数据分布”**，这使 RL 在推理泛化上优于纯 SFT（学什么和reward需要人来指定，怎么学是LLM根据当前自己的state探索决定的）。
- 产业用工将两极分化：顶层探索（研究/垂直应用）人数增、多数“执行层”岗位因工具和 pipeline 自动化而减少。
- 开/闭源并非二选一，“用途导向”才是关键：做平台与社区时开源更有意义，做个性化搜索/推荐等场景则倾向闭源。
- 他个人目标是**把前沿研究与自动化 pipeline 结合，成为“超级研究员”**。这既是研究范式升级，也是人才竞争的新答案。

## 全文
### 片头预告与核心观点（00:00:00 - 00:01:06）
**田渊栋**：我在备裁之前已经有 offer 了，在公司待得久，可能正好是出来看看的一次时机。
**采访者**：你觉得 LLM 是正确的路线吗？
**田渊栋**：LLM 很有意思，但不确定是不是“正确”。我觉得 **Scaling Law（扩展规律）指向的是一个悲观的未来**。
**采访者**：现在这些模型最大的问题是什么？
**田渊栋**：数据量需求非常大，像自动驾驶早期那样前期进展快、后期卡在“好数据/好 insight 稀缺”。
**采访者**：怎么看 RL？
**田渊栋**：==**强化学习最大的好处是主动学习，能对训练数据的分布产生积极影响**==。
**采访者**：你在 FAIR 还有遗憾吗？
**田渊栋**：应该做更多工程；最大收获是 2018 年后形成了自己的 research taste（研究品味）。
**采访者**：你的下一步是什么？
（见后文）

### 开场与背景：Meta 裁员与本期聚焦（00:01:08 - 00:02:32）
**陈倩**：2025-10-22，Meta 批准裁减 AI 部门约600人，主要集中在“超智能实验室”的核心研发。上期我们讲了裁员原因、开源路线的挫折和新 AI 负责人 Alex Wang 的可能重塑。本期放出对“研究总监（钱菲尔）”和 **AI 科学家田渊栋**的完整采访，聚焦 LLM 路线、开/闭源、Research Lab 的意义、以及 AI 人才在“研发与工程”之间的选择。

### 采访开始：轻松寒暄（00:02:33 - 00:03:00）
**陈倩**：你还穿着 FAIR 的衣服。
**田渊栋**：我们这种人不太 care 穿着，公司发什么就穿什么。有时候也会换啦。

### 被裁与心态：offer 在先、裁员加速了决定（00:03:00 - 00:05:03）
**陈倩**：过去几天怎么样？很多人来 reach out？
**田渊栋**：我在“备裁”前就拿到 offer，也提前和 manager 沟通过“不太爽，可能要 look around”。裁员并不意外；我本想再待一阵，卡还在，还能做些东西。被裁等于是加速了这个 personal choice。最近许多国内外大厂高层、小公司、甚至科研/高校机会都来找，我还在想，还没决定，离裁员不到一周。

### 行业趋势：自动化提升，人力需求下降（00:05:04 - 00:06:30）
**陈倩**：600 人还是很多。这是 Meta 个例还是行业趋势？
**田渊栋**：更像行业趋势。AI 的自动化程度极高：今天需要大规模标注，明天可能不需要；以前模型挂了要人电话救火，现在系统化、自动化工具完善后，这类负担也减少。**pipeline 成熟度提升 → 需要的人变少**。

### 工作形态变化：团队更小、agent 更多（00:06:30 - 00:07:50）
**陈倩**：这会影响更多从业者？
**田渊栋**：长期看“传统意义上的雇佣式工作”会变少。如果我去带团队或创业，拿到这些工具，会发现很多事自动化了，**agent** 可以做很多执行。总体是“做 AI 的人少一些，用 AI 做事的人多很多”。

### Foundation Model 人才结构：研究/应用增，执行层缩（00:07:50 - 00:09:02）
**陈倩**：做 Foundation Model 的人会变少吗？
**田渊栋**：探索性研究会更多，但“把模型训起来”的工程岗位会更少，因为流程可复用。做研究和垂直应用的人会增加。
**采访者**：中间层的执行会减少？
**田渊栋**：对。工具成熟后，**重复性工程**缩减。

### 裁员前在 FAIR：救火与论文（00:09:03 - 00:10:01）
**采访者**：裁员前在 FAIR 做什么？
**田渊栋**：年初被抽调去内部项目“救火”，fix 问题、拉 data 等。个人也与外部合作：4 月有篇关于思维链（Chain-of-Thought, CoT）理论分析的论文，补全了 CoT 的理论理解，影响力不错。

### 开/闭源的下一步：用途导向而非二元对立（00:10:01 - 00:13:13）
**采访者**：前沿模型竞争激烈，开源会不会被“越拉越远”？
**田渊栋**：硅谷仍会有人做开源，比如 reflection 类公司、AI2 等。关键不在“开/闭”，而在“有什么用”。聊天/效率工具大厂会做；**科学发现、垂直领域小公司能做**。是否需要“最强模型”因问题而异。
- 若你要做平台/社区，开源很合理：模型能调用 standard toolchain（标准工具链），围绕模型搭平台。
- 若是 personalised search / personalised recommendation 这类，通常会闭源或各自训练。
结论：**看 purpose，而非给“开/闭源”下定论**。

### LLM 是否正确路线：科学家心态与最大痛点（00:13:14 - 00:15:36）
**采访者**：LLM 是正确路线吗？
**田渊栋**：LLM 有意思，但科学家不会满足于现框架，必须找更好的。
最大问题是数据效率：人类用很少 token（人生中的文本 token 总量远少于模型训练）就能学会本质；模型训练动辄 10^X 级别，**人与模型样本效率差距可达千倍**。许多人类顶尖发现并非靠“海量数据”。

### 训练范式可能变：也许不是梯度下降（00:15:36 - 00:16:16）
**田渊栋**：也许有一天我们不再用 gradient descent（梯度下降），而采用新的训练框架。这可能改变整个训练范式，值得探索。

### RL vs SFT：主动学习、重塑分布与推理泛化（00:16:16 - 00:19:12）
**陈倩**：Andrej Karpathy 最近对 RL 有争议性观点，你怎么看 RL？
**田渊栋**：我一直做这方向。RL 本质是搜索过程：面对难题去搜，在搜索中采到的数据，质量通常优于被动喂给的监督数据。上课像 SFT，自学解题像 RL；**后者学到的能力更本质、泛化更强**。很多工作也显示 RL 在推理任务上优于 SFT；大量 SFT 甚至有“记程序不泛化”的风险。
范式上，RL 与 SFT 只是“如何改权重”的不同实现，未来可能统一。但我强调：**RL 的关键不是 loss，而是“主动数据采集→改变分布”**。

### AGI 时间线、与 GPT-5 的 self-play 协作（00:19:12 - 00:22:07）
**田渊栋**：我同意“AGI 还有十年”的判断更可信。我==**最近一篇文章就是我和 GPT-5 通过 self-play 合作完成的：我提出问题与目标，它会给出 formulation（形式化）；我指出关键缺陷或方向，它再深入，直到得到好结果**。结论是：**高层 human insights / knowledge 仍是现在模型所缺**==，没有这些不能称 AGI。人类在少样本下能看见本质，而模型需要几百上千样本才“看出轮廓”。

### Scaling Law 的悲观与“效率时代”的必要（00:22:07 - 00:24:13）
**田渊栋**：以前大家都知道“加数据/算力就更好”是 trivially true，但这不是我们想要的未来。**Scaling Law（扩展规律）若继续主导，最终会走向算力与能源的极限**。我们需要的是更高效的模型与更深入的机制理解，而非一味堆料。

### 即使停滞，影响仍巨大（00:24:13 - 00:25:04）
**田渊栋**：就算未来几年模型能力停滞，社会影响仍然会非常大。它能自动化许多事、显著增强个体能力——我自己已明显感到“加上大模型的我，远强于从前的我”。

### 目标：自动化研究，成为“超级研究员”（00:25:04 - 00:26:34）
**陈倩**：你接下来做前沿还是应用？
**田渊栋**：最好结合：做前沿研究，同时把研究流程自动化。agent 能帮我做邮件、待办、琐事，但更重要的是：==**AI 能否辅助“需要人类 insights 的高级活动”==（高难科学问题）**。如果能，我会成为“超级研究员”，也把这些工具普惠给他人。

### O1 之前的 reasoning 研究（00:26:36 - 00:28:33）
**田渊栋**：在 O1（OpenAI o1）发布前，我们已系统研究思维链：
- 长 CoT（Chain-of-Thought）在采样上非常昂贵，不利于数据效率；短 CoT 反而能用更少样本取得好效果。
- 我们做了 ==**continuous CoT / hidden space inference**（在连续空间进行隐变量推理）==，半年内引发大量引用。
- 提出了“Dual-form / 混合思维”：==**长短思维联合训练**==，效果优于单训长或单训短。如今已成很多思维模型的“标配”。

### 在 FAIR 的遗憾与收获：工程×研究的双栖（00:28:33 - 00:31:13）
**陈倩**：在 FAIR 还有遗憾吗？
**田渊栋**：可能该做更多工程。刚去时我工程很多（比如围棋项目），甚至被说“研究科学家怎天天写代码”。2015-2018 偏工程，2018 至今偏研究。==现在时代更青睐“**工程与研究都强**”的人。最大收获是形成了 **research taste（研究品味）**：知道“**哪些问题有意义**、如何走长路”。==只有工程不够，因为可能不知道做的难题“为何有用”。

### 人才与选择：别追“最稀缺”，做自己长期想做的（00:31:13 - 00:34:19）
**陈倩**：当下什么 AI 人才最稀缺？
**田渊栋**：别纠结谁最稀缺，因为两年就会变。过去“市场信号→大学扩招→人才供给”的慢周期已被打乱；如今全世界一起学，学得更快更好的人很多，跟风容易“永远追在别人后面”。**与其追热点，不如把“个人长期兴趣”与“对未来的判断”拼成独特组合**。

### Research Lab 的未来：不是非黑即白（00:34:19 - 00:37:28）
**陈倩**：理想化的 Research Lab 还存在吗？
**田渊栋**：大厂不是铁板一块，很多组仍有 research freedom；startup 也有。研究会持续，只是形态可能==**从“大院制”转向“游击战”**==：**很多有理想的小团队在前沿处持续输出**。不是“有/无研究”的二元，而是光谱分布。

### 下一步：Aim high，倒推可行路径（00:37:29 - 00:38:32）
**陈倩**：你的下一步是什么？
**田渊栋**：还没定。理想是能“既赋能科研、又能产生外部价值”的方向。==**先 aim high（高设目标），再倒推匹配路径**，通常更能找到好的路。==

### 结语（00:38:32 - 00:39:03）
**陈倩**：以上是对田渊栋的完整采访，也期待他在“前沿研究×工程应用”上找到平衡的新角色。
**旁白/制作团队**：欢迎点赞转发支持硅谷101，我们下期见。

——
加粗为我认为较重要、具洞见或非共识的观点。术语、人名等保留原文（必要时附中文释义）。对零碎的英文口语进行了中文整理，关键表达如 RL、SFT、Scaling Law、formulation、self-play、Chain-of-Thought 等均保留原文。

## 欢迎交流与合作
目前主要兴趣是探索agent的真正落地，想进一步交流可加微信（微信号：cleezhang），一些[自我介绍](https://lee-agi.github.io/85ed64eda0/)。

> 本文发表于 2025-11-13_周四。
